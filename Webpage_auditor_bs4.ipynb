{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYJvZs4t0R6cdjEeBemRQJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plus2net/Python-basics/blob/main/Webpage_auditor_bs4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](https://www.plus2net.com/images/top2.jpg)        Read more on [Webpage Auditor. ](https://www.plus2net.com/python/bs4-auditor.php)"
      ],
      "metadata": {
        "id": "B-rFbH1FpBcT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "493cac40"
      },
      "source": [
        "# Task\n",
        "This simple_auditor.py script gives you a fast, offline way to check a page’s SEO and AI-readiness without depending on third-party APIs or rate limits. By fixing the missing elements it highlights, you improve your content’s visibility for both search engines and AI tools."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple_auditor.py\n",
        "# Minimal, API-key-free webpage auditor with case-insensitive meta extraction.\n",
        "# Change `url_to_audit` to target another page.\n",
        "\n",
        "import re\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# ====== Change this URL to audit another page ======\n",
        "url_to_audit = \"https://en.wikipedia.org/wiki/Web_page\"\n",
        "\n",
        "UA = \"Mozilla/5.0 (compatible; AI-Ready-Auditor/1.1; +https://example.com)\"\n",
        "TIMEOUT = 30\n",
        "\n",
        "\n",
        "def fetch_html(url: str) -> tuple[int, str]:\n",
        "    r = requests.get(url, headers={\"User-Agent\": UA}, timeout=TIMEOUT)\n",
        "    return r.status_code, r.text\n",
        "\n",
        "\n",
        "def get_meta_by_name(soup: BeautifulSoup, meta_name: str):\n",
        "    \"\"\"\n",
        "    Case-insensitive fetch of  content.\n",
        "    Matches NAME=\"DESCRIPTION\" as well as name=\"description\".\n",
        "    \"\"\"\n",
        "    tag = soup.find(\"meta\", attrs={\"name\": re.compile(rf\"^{re.escape(meta_name)}$\", re.I)})\n",
        "    return (tag.get(\"content\") or \"\").strip() if tag and tag.get(\"content\") else None\n",
        "\n",
        "\n",
        "def get_meta_by_property(soup: BeautifulSoup, prop_name: str):\n",
        "    \"\"\"\n",
        "    Case-insensitive fetch of  content (e.g., og:description).\n",
        "    \"\"\"\n",
        "    tag = soup.find(\"meta\", attrs={\"property\": re.compile(rf\"^{re.escape(prop_name)}$\", re.I)})\n",
        "    return (tag.get(\"content\") or \"\").strip() if tag and tag.get(\"content\") else None\n",
        "\n",
        "\n",
        "def extract_schema_flags(json_ld_blocks: list[str]):\n",
        "    \"\"\"\n",
        "    Simple presence checks for common schema types used in articles.\n",
        "    \"\"\"\n",
        "    j = \"\\n\".join(json_ld_blocks)\n",
        "    has_faq = \"FAQPage\" in j\n",
        "    has_howto = \"HowTo\" in j\n",
        "    has_video = \"VideoObject\" in j\n",
        "    return has_faq, has_howto, has_video\n",
        "\n",
        "\n",
        "def analyze(url: str):\n",
        "    status, html = fetch_html(url)\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "    # ---- Metadata (case-insensitive for meta name/property values) ----\n",
        "    title = soup.title.string.strip() if soup.title and soup.title.string else None\n",
        "\n",
        "    # Description: name=description (any case) with fallback to og:description\n",
        "    meta_description = get_meta_by_name(soup, \"description\") or get_meta_by_property(soup, \"og:description\")\n",
        "    meta_description_length = len(meta_description) if meta_description else None\n",
        "\n",
        "    # Keywords (optional, informational)\n",
        "    meta_keywords = get_meta_by_name(soup, \"keywords\")\n",
        "\n",
        "    # Viewport (sanity check for mobile friendliness)\n",
        "    meta_viewport = get_meta_by_name(soup, \"viewport\")\n",
        "\n",
        "    # ---- Headings ----\n",
        "    h1_tag = soup.find(\"h1\")\n",
        "    h1 = h1_tag.get_text(strip=True) if h1_tag else None\n",
        "\n",
        "    # ---- Canonical (case-insensitive rel) ----\n",
        "    canonical_tag = soup.find(\"link\", rel=lambda v: v and v.lower() == \"canonical\")\n",
        "    canonical_url = canonical_tag.get(\"href\") if canonical_tag else None\n",
        "\n",
        "    # ---- GA4 (G-XXXXXXXX) ----\n",
        "    ga4_ids = list(sorted(set(re.findall(r\"G-[A-Z0-9]{6,12}\", html))))\n",
        "    has_ga4 = bool(ga4_ids)\n",
        "\n",
        "    # ---- Open Graph / Twitter (case-insensitive) ----\n",
        "    og_tags = {\n",
        "        t.get(\"property\"): t.get(\"content\")\n",
        "        for t in soup.find_all(\"meta\", attrs={\"property\": re.compile(r\"^og:\", re.I)})\n",
        "        if t.get(\"property\") and t.get(\"content\")\n",
        "    }\n",
        "    twitter_tags = {\n",
        "        t.get(\"name\"): t.get(\"content\")\n",
        "        for t in soup.find_all(\"meta\", attrs={\"name\": re.compile(r\"^twitter:\", re.I)})\n",
        "        if t.get(\"name\") and t.get(\"content\")\n",
        "    }\n",
        "\n",
        "    # ---- Images / alt coverage ----\n",
        "    imgs = soup.find_all(\"img\")\n",
        "    images_total = len(imgs)\n",
        "    images_with_alt = sum(1 for i in imgs if (i.get(\"alt\") or \"\").strip())\n",
        "    images_alt_coverage_pct = round((images_with_alt / images_total * 100), 2) if images_total else 0.0\n",
        "\n",
        "    # ---- Links (internal vs external) ----\n",
        "    parsed = urlparse(url)\n",
        "    base_host = parsed.netloc\n",
        "    internal_links, external_links = 0, 0\n",
        "    for a in soup.find_all(\"a\", href=True):\n",
        "        href = a.get(\"href\")\n",
        "        p = urlparse(href)\n",
        "        if not p.netloc or p.netloc == \"\" or p.netloc == base_host:\n",
        "            internal_links += 1\n",
        "        else:\n",
        "            external_links += 1\n",
        "\n",
        "    # ---- Schema JSON-LD presence ----\n",
        "    json_ld_blocks = [t.get_text() for t in soup.find_all(\"script\", type=\"application/ld+json\")]\n",
        "    has_faq_schema, has_howto_schema, has_video_schema = extract_schema_flags(json_ld_blocks)\n",
        "\n",
        "    # ---- Breadcrumbs ----\n",
        "    breadcrumbs_present = bool(soup.select('[itemtype*=\"BreadcrumbList\" i], nav.breadcrumb, ol.breadcrumb'))\n",
        "\n",
        "    # ---- robots.txt & sitemap hint ----\n",
        "    root = f\"{parsed.scheme}://{parsed.netloc}\"\n",
        "    sitemap_present = False\n",
        "    try:\n",
        "        rr = requests.get(f\"{root}/robots.txt\", headers={\"User-Agent\": UA}, timeout=10)\n",
        "        if rr.ok and \"sitemap\" in rr.text.lower():\n",
        "            sitemap_present = True\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return {\n",
        "        \"url\": url,\n",
        "        \"http_status\": status,\n",
        "        \"title\": title,\n",
        "        \"title_length\": len(title) if title else None,\n",
        "        \"meta_description\": meta_description,\n",
        "        \"meta_description_length\": meta_description_length,\n",
        "        \"meta_keywords\": meta_keywords,\n",
        "        \"meta_viewport_present\": bool(meta_viewport),\n",
        "        \"h1\": h1,\n",
        "        \"canonical_url\": canonical_url,\n",
        "        \"ga4_ids\": ga4_ids,\n",
        "        \"og_tags_present\": bool(og_tags),\n",
        "        \"twitter_tags_present\": bool(twitter_tags),\n",
        "        \"images_total\": images_total,\n",
        "        \"images_with_alt\": images_with_alt,\n",
        "        \"images_alt_coverage_pct\": images_alt_coverage_pct,\n",
        "        \"internal_links\": internal_links,\n",
        "        \"external_links\": external_links,\n",
        "        \"has_faq_schema\": has_faq_schema,\n",
        "        \"has_howto_schema\": has_howto_schema,\n",
        "        \"has_videoobject_schema\": has_video_schema,\n",
        "        \"breadcrumbs_present\": breadcrumbs_present,\n",
        "        \"sitemap_present\": sitemap_present\n",
        "    }\n",
        "\n",
        "\n",
        "def print_summary(r: dict):\n",
        "    print(\"\\n=== AI-Ready Webpage Audit Summary ===\")\n",
        "    print(\"URL:\", r[\"url\"])\n",
        "    print(\"HTTP Status:\", r[\"http_status\"])\n",
        "\n",
        "    # Title / Meta\n",
        "    print(f\"Title ({r['title_length']} chars):\", \"Present\" if r[\"title\"] else \"Missing\")\n",
        "    print(\n",
        "        f\"Meta Description ({r['meta_description_length']} chars):\",\n",
        "        \"Present\" if r[\"meta_description\"] else \"Missing\"\n",
        "    )\n",
        "    print(\"Meta Keywords:\", \"Present\" if r.get(\"meta_keywords\") else \"Missing\")\n",
        "    print(\"Viewport Meta:\", \"Present\" if r.get(\"meta_viewport_present\") else \"Missing\")\n",
        "\n",
        "    # Structure\n",
        "    print(\"H1:\", \"Present\" if r[\"h1\"] else \"Missing\")\n",
        "    print(\"Canonical URL:\", r[\"canonical_url\"] or \"Missing\")\n",
        "\n",
        "    # Tracking / Social\n",
        "    print(\"GA4 IDs:\", r[\"ga4_ids\"] if r[\"ga4_ids\"] else \"None Found\")\n",
        "    print(\"OpenGraph Tags:\", r[\"og_tags_present\"])\n",
        "    print(\"Twitter Tags:\", r[\"twitter_tags_present\"])\n",
        "\n",
        "    # Media / Links\n",
        "    print(f\"Images with alt: {r['images_with_alt']}/{r['images_total']} ({r['images_alt_coverage_pct']}%)\")\n",
        "    print(\"Internal Links:\", r[\"internal_links\"], \"| External Links:\", r[\"external_links\"])\n",
        "\n",
        "    # Schema / Nav\n",
        "    print(\"FAQ Schema:\", r[\"has_faq_schema\"])\n",
        "    print(\"HowTo Schema:\", r[\"has_howto_schema\"])\n",
        "    print(\"VideoObject Schema:\", r[\"has_videoobject_schema\"])\n",
        "    print(\"Breadcrumbs:\", r[\"breadcrumbs_present\"])\n",
        "    print(\"Sitemap in robots.txt:\", r[\"sitemap_present\"])\n",
        "    print(\"======================================\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    report = analyze(url_to_audit)\n",
        "    print_summary(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd-nepKxHsBR",
        "outputId": "37bb80cf-25f7-42bf-bf62-507a6ad3801b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== AI-Ready Webpage Audit Summary ===\n",
            "URL: https://en.wikipedia.org/wiki/Web_page\n",
            "HTTP Status: 200\n",
            "Title (20 chars): Present\n",
            "Meta Description (None chars): Missing\n",
            "Meta Keywords: Missing\n",
            "Viewport Meta: Present\n",
            "H1: Present\n",
            "Canonical URL: https://en.wikipedia.org/wiki/Web_page\n",
            "GA4 IDs: None Found\n",
            "OpenGraph Tags: True\n",
            "Twitter Tags: False\n",
            "Images with alt: 5/9 (55.56%)\n",
            "Internal Links: 263 | External Links: 123\n",
            "FAQ Schema: False\n",
            "HowTo Schema: False\n",
            "VideoObject Schema: False\n",
            "Breadcrumbs: False\n",
            "Sitemap in robots.txt: True\n",
            "======================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}