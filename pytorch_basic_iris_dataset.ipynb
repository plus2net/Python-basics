{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtfaCA5mUW5TQ94p+Gux9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plus2net/Python-basics/blob/main/pytorch_basic_iris_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4TJ6gzU21dUn",
        "outputId": "334e7adb-17b1-4cf3-8dbb-4d4135b3fb69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 1.0219\n",
            "Epoch 2/30, Loss: 0.7556\n",
            "Epoch 3/30, Loss: 0.4410\n",
            "Epoch 4/30, Loss: 0.2688\n",
            "Epoch 5/30, Loss: 0.1926\n",
            "Epoch 6/30, Loss: 0.1381\n",
            "Epoch 7/30, Loss: 0.1011\n",
            "Epoch 8/30, Loss: 0.0942\n",
            "Epoch 9/30, Loss: 0.0828\n",
            "Epoch 10/30, Loss: 0.0574\n",
            "Epoch 11/30, Loss: 0.0564\n",
            "Epoch 12/30, Loss: 0.0582\n",
            "Epoch 13/30, Loss: 0.0473\n",
            "Epoch 14/30, Loss: 0.0550\n",
            "Epoch 15/30, Loss: 0.0431\n",
            "Epoch 16/30, Loss: 0.0403\n",
            "Epoch 17/30, Loss: 0.0486\n",
            "Epoch 18/30, Loss: 0.0436\n",
            "Epoch 19/30, Loss: 0.0486\n",
            "Epoch 20/30, Loss: 0.0365\n",
            "Epoch 21/30, Loss: 0.0365\n",
            "Epoch 22/30, Loss: 0.0348\n",
            "Epoch 23/30, Loss: 0.0354\n",
            "Epoch 24/30, Loss: 0.0341\n",
            "Epoch 25/30, Loss: 0.0377\n",
            "Epoch 26/30, Loss: 0.0599\n",
            "Epoch 27/30, Loss: 0.0673\n",
            "Epoch 28/30, Loss: 0.0410\n",
            "Epoch 29/30, Loss: 0.0336\n",
            "Epoch 30/30, Loss: 0.0435\n",
            "Test Accuracy: 0.9667\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # shape (150, 4)\n",
        "y = iris.target  # shape (150,)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader\n",
        "train_ds = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define the neural network\n",
        "class IrisNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(4, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 3)  # 3 classes\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = IrisNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in train_loader:\n",
        "        preds = model(xb)\n",
        "        loss = criterion(preds, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = (predicted == y_test).float().mean().item()\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(),'smo.pt') # creating a Model file and saving"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the above created model ( last line )  file to load the pytorch model. Without this file also we can pass the model to below code."
      ],
      "metadata": {
        "id": "o6dvMzvV5lMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=IrisNN()\n",
        "model.load_state_dict(torch.load('smo.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdIJWPUW4MTH",
        "outputId": "719d5555-9b2d-44bf-e074-4d735e1e614d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Example raw input: [sepal length, sepal width, petal length, petal width]\n",
        "# e.g., a flower with measurements 5.1, 3.5, 1.4, 0.2\n",
        "raw_sample = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
        "\n",
        "# Scale using the previously fitted StandardScaler\n",
        "sample_scaled = scaler.transform(raw_sample)\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "sample_tensor = torch.tensor(sample_scaled, dtype=torch.float32)\n",
        "\n",
        "# Perform inference\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(sample_tensor)\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    pred_class = torch.argmax(probs, dim=1).item()\n",
        "    pred_prob = probs[0, pred_class].item()\n",
        "\n",
        "# Map numeric prediction to species name\n",
        "species = iris.target_names[pred_class]\n",
        "\n",
        "print(f\"Predicted species: {species} (class {pred_class})\")\n",
        "print(f\"Confidence: {pred_prob:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2e6yzZz2EaQ",
        "outputId": "c9823031-529f-4746-b16b-5fb7f102d09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted species: setosa (class 0)\n",
            "Confidence: 1.0000\n"
          ]
        }
      ]
    }
  ]
}