{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsDoftX57zNu+OZwAbP3iZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plus2net/Python-basics/blob/main/Gemini_without_api_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](https://www.plus2net.com/images/top2.jpg)        More on  [Gemini API  ](https://www.plus2net.com/python/ai-gemini.php)"
      ],
      "metadata": {
        "id": "B_i39EkVBZun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic use without API"
      ],
      "metadata": {
        "id": "dn0GDAukhpq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import ai\n",
        "response = ai.generate_text(\"What is the capital of India?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "T-HNhr06hlNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9499b803-9aa8-44de-9459-6184d768c9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of India is **New Delhi**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listing all Models available"
      ],
      "metadata": {
        "id": "eZNc7GSih51U"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62171e20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a501fc1-be68-4866-94cb-2284d107db73"
      },
      "source": [
        "# @title List available models\n",
        "from google.colab import ai\n",
        "\n",
        "ai.list_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['google/gemini-2.5-flash', 'google/gemini-2.5-flash-lite']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Give the model name as input"
      ],
      "metadata": {
        "id": "ZUMhUok8hfCE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27b14590",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33f0b4e-3848-4897-c974-9cd6721fa001"
      },
      "source": [
        "# @title Choose a different model\n",
        "from google.colab import ai\n",
        "\n",
        "response = ai.generate_text(\"What is the capital of England\", model_name='google/gemini-2.5-flash-lite')\n",
        "print(response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of England is **London**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ai.generate_text(..., stream=True) is described as streaming real-time text generation."
      ],
      "metadata": {
        "id": "RBeXY9mVDror"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Simple streaming example\n",
        "from google.colab import ai\n",
        "\n",
        "stream = ai.generate_text(\"Tell me a short story.\", stream=True)\n",
        "for text in stream:\n",
        "  print(text, end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZDptnPaDlQD",
        "outputId": "61d24577-3b5f-42e0-cc8d-11150c5b1854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elara lived in a cottage woven from silence and old lace, her days marked by the creak of floorboards and the distant call of a hawk. Her only companion was a persistent draft beneath the back door and a garden unruly with wild roses.\n",
            "\n",
            "One crisp autumn morning, a dream clung to her like dew. She'd dreamt of the Whispering Oak, the ancient sentinel at the forest's edge, a tree whose roots clawed at the earth like gnarled fingers. In her dream, a single, iridescent blue feather had nestled in a hollow beneath its oldest root, and the feather had glowed.\n",
            "\n",
            "Despite the ache in her knees, Elara found her stoutest walking stick and set off. The path to the oak was long disused, reclaimed by thorny brambles and a carpet of fallen leaves. Each step was an effort, but the dream pulled her onward, a whisper of forgotten magic.\n",
            "\n",
            "When she finally reached the gnarled behemoth, its branches stretching like arms to the sky, she squinted, trying to recall the dream's exact location. Then, a glint of sky-blue caught her eye. Not a feather, but a shard of pottery, partially buried. Carefully, she knelt, her fingers trembling as she brushed away the soil.\n",
            "\n",
            "It wasn't a feather, but a small, intricately carved wooden box, worn smooth by time and damp earth. It had clearly been hidden there for decades. With a rusty click, the clasp gave way.\n",
            "\n",
            "Inside, nestled on a bed of dried moss, were two items: a tiny, tarnished silver locket and a folded, brittle piece of paper. Elara's heart thrummed. She recognized the locket instantly – it was identical to the one she'd worn as a child, a gift from her best friend, Lily, who had moved away abruptly when they were ten.\n",
            "\n",
            "The note, written in a child's looping hand, was faded but legible:\n",
            "\n",
            "*“Dear Elara, If you ever find this, it means you remembered our secret place. I left this for you. Promise me you’ll always find the magic. – Lily.”*\n",
            "\n",
            "A tear traced a path down Elara's wrinkled cheek. Lily, with her wild red hair and infectious laugh. The oak had been their fortress, their confessional. She looked up at the ancient tree, then back at the locket and the note. The \"magic\" Lily spoke of wasn't some grand illusion, but the simple, enduring thread of connection, the memory that could bridge decades, waiting patiently beneath an old oak tree.\n",
            "\n",
            "The draft beneath her back door suddenly felt a little less lonely."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the sample student data from the url\n",
        "!wget https://www.plus2net.com/python/download/student.xlsx"
      ],
      "metadata": {
        "id": "MZQqXrXhP4L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_excel('student.xlsx')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Pg1twWTSJeXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2df60c5"
      },
      "source": [
        "## Prepare Data for Model\n",
        "\n",
        "### Subtask:\n",
        "Convert the DataFrame into a string format suitable for the AI model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e79459e4"
      },
      "source": [
        "**Reasoning**:\n",
        "To provide the data to the AI model, I will convert the entire `df` DataFrame into a string representation using `df.to_string()`. This will allow the AI model to process the tabular data as text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea4a29cc"
      },
      "source": [
        "df_string = df.to_string()\n",
        "print(df_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09d3dc9f"
      },
      "source": [
        "## Ask Questions to AI Model\n",
        "\n",
        "### Subtask:\n",
        "Ask the AI model to find the student with the highest mark from the provided data string."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8770cd08"
      },
      "source": [
        "**Reasoning**:\n",
        "I will construct a prompt that includes the DataFrame as a string and explicitly asks the AI model to identify the student with the highest mark from the 'mark' column. This allows the AI to perform the 'analysis' and extract the name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "990e5efb",
        "outputId": "6cf1a1e1-8a11-43e1-f67b-91689fc2e8fa"
      },
      "source": [
        "from google.colab import ai\n",
        "\n",
        "question = \"From the following student data, which student has the highest mark? Please only provide the student's name.\\n\\n\" + df_string\n",
        "ai_response = ai.generate_text(question, model_name='google/gemini-2.5-flash')\n",
        "print(ai_response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kenn Rein\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask for all details of the student who got highest mark."
      ],
      "metadata": {
        "id": "N9x7cw3KMHX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Give me the name, class , mark for the  student who has the highest mark.\\n\\n\"\n",
        "ai_response = ai.generate_text(question, model_name='google/gemini-2.5-flash')\n",
        "print(ai_response)"
      ],
      "metadata": {
        "id": "7Mmv9pJuL1RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It does not maintain the historic information, by not giving the df_string it can't reply by using previous posted information."
      ],
      "metadata": {
        "id": "nuAnyzpEM_ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Give me the average mark for class Four.\\n\\n\"\n",
        "#question = \"Give me the average mark for class Four.\\n\\n\" + df_string\n",
        "ai_response = ai.generate_text(question, model_name='google/gemini-2.5-flash')\n",
        "print(ai_response)"
      ],
      "metadata": {
        "id": "gQ3uR5hyMMoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From a list to dictionary"
      ],
      "metadata": {
        "id": "S_flP4Aa-0Lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import ai\n",
        "countries=['India','USA','Japan']\n",
        "my_str=\",\".join(map(str,countries)) # string from List\n",
        "question = \"Create one Python dictionary by using the list names as key and capitals of the countries as values .\\n\\n\" + my_str\n",
        "ai_response = ai.generate_text(question, model_name='google/gemini-2.5-flash')\n",
        "print(ai_response)"
      ],
      "metadata": {
        "id": "Olz8CInBM3wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take user input inside a loop and dispaly the output from AI model."
      ],
      "metadata": {
        "id": "V7jaxLHq7TwX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8cc8d4c"
      },
      "source": [
        "from google.colab import ai\n",
        "\n",
        "model_name = 'google/gemini-2.5-flash'\n",
        "\n",
        "print(f\"You can now ask questions to the model ({model_name}). Type 'exit' to stop.\")\n",
        "\n",
        "while True:\n",
        "  user_question = input(\"Your question: \")\n",
        "  if user_question.lower() == 'exit':\n",
        "    break\n",
        "\n",
        "  response = ai.generate_text(user_question, model_name=model_name)\n",
        "  print(\"Model's answer:\", response)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}